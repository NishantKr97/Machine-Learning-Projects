# Perceptron Model
In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers 
(functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not).
<br>It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor 
function combining a set of weights with the feature vector.
<br>
In the modern sense, the perceptron is an algorithm for learning a binary classifier: a function that maps its input x (a real-valued vector) to an output value f ( x ) {\displaystyle f(x)} f(x) (a single binary value):
<br><br>
    f ( x ) = { 1 if    w ⋅ x + b > 0
    <br>      {0 otherwise 
    <br>

where w is a vector of real-valued weights, w ⋅ x is the dot product
<br>
∑ i = w i . x i <br> where i varies from 0 to m, where m is the number of inputs to the perceptron and b is the bias. The bias shifts the decision boundary away from the origin and does not depend on any input value.
<br><br>
This project implememts Perceptron model for the Basic Logic Gates like<br>
1. OR Gate<br>
2. AND Gate<br>
3. NOR Gate<br>
4. NAND Gate<br>
